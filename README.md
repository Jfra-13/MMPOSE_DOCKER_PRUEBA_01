# MMPose â€“ Dockerized Runtime

![CUDA](https://img.shields.io/badge/CUDA-12.1-76B900?logo=nvidia)
![PyTorch](https://img.shields.io/badge/PyTorch-2.4-EE4C2C?logo=pytorch)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker)

Entorno reproducible y listo para usar que ejecuta **estimaciÃ³n de pose con MMPose** dentro de Docker, aprovechando GPU NVIDIA con CUDA 12.1.

> âœ¨ **Todo incluido**: MMPose se clona e instala automÃ¡ticamente dentro del contenedor. No necesitas instalaciones locales.

**Probado en**: Windows 11 + Docker Desktop (WSL2) con GPU NVIDIA

---

## ğŸ“‹ Tabla de Contenidos

- [PreparaciÃ³n del Entorno (GPU + Docker)](#-preparaciÃ³n-del-entorno-gpu--docker)
  - [1. Verificar tu GPU](#1ï¸âƒ£-verificar-tu-gpu)
  - [2. Instalar Drivers NVIDIA y CUDA](#2ï¸âƒ£-instalar-drivers-nvidia-y-cuda)
  - [3. Instalar Docker con Soporte GPU](#3ï¸âƒ£-instalar-docker-con-soporte-gpu)
  - [4. Verificar que Docker Detecta la GPU](#4ï¸âƒ£-verificar-que-docker-detecta-la-gpu)
  - [5. Flujo Recomendado](#5ï¸âƒ£-flujo-recomendado-antes-de-correr-el-proyecto)
- [Requisitos del Proyecto](#-requisitos-del-proyecto)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [GuÃ­a RÃ¡pida de Inicio](#-guÃ­a-rÃ¡pida-de-inicio)
  - [1. Construir la Imagen](#1-construir-la-imagen)
  - [2. Iniciar el Contenedor](#2-iniciar-el-contenedor)
  - [3. Verificar InstalaciÃ³n](#3-verificar-instalaciÃ³n)
- [Uso: Procesamiento de Videos](#-uso-procesamiento-de-videos)
- [Uso: Tiempo Real (CÃ¡mara)](#-uso-tiempo-real-cÃ¡mara)
- [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)
- [Preguntas Frecuentes](#-preguntas-frecuentes)

---

## ğŸš€ PreparaciÃ³n del Entorno (GPU + Docker)

Este proyecto requiere **aceleraciÃ³n por GPU** para un rendimiento Ã³ptimo en la estimaciÃ³n de poses.  
A continuaciÃ³n se detallan los pasos previos necesarios antes de clonar y ejecutar el repositorio.

---

### 1ï¸âƒ£ Verificar tu GPU

Abre **PowerShell** o **CMD** en Windows y ejecuta:

```bash
nvidia-smi
```

Si tu tarjeta grÃ¡fica es detectada, verÃ¡s algo similar a esto:

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.146   Driver Version: 535.146   CUDA Version: 12.2          |
| GPU Name        Persistence-M| Bus-Id ... Memory-Usage ...                 |
+-----------------------------------------------------------------------------+
```

âœ… Esto confirma que tienes drivers NVIDIA funcionando.

---

### 2ï¸âƒ£ Instalar Drivers NVIDIA y CUDA

1. **Descarga los drivers oficiales NVIDIA**:  
   ğŸ‘‰ https://www.nvidia.com/Download/index.aspx

2. **Descarga e instala CUDA Toolkit** (elige la versiÃ³n que coincida con tu GPU y drivers):  
   ğŸ‘‰ https://developer.nvidia.com/cuda-downloads

3. Durante la instalaciÃ³n marca **"Include Driver"** si no lo tienes actualizado.

4. **Verifica CUDA** con:
   ```bash
   nvcc --version
   ```

---

### 3ï¸âƒ£ Instalar Docker con Soporte GPU

1. **Descarga e instala Docker Desktop**:  
   ğŸ‘‰ https://www.docker.com/products/docker-desktop/

2. Activa la opciÃ³n **"Use WSL 2 based engine"** en configuraciÃ³n de Docker.

3. **Instala el NVIDIA Container Toolkit** (permite que Docker acceda a la GPU):

   Abre **PowerShell (Admin)** y ejecuta:
   ```powershell
   wsl --update
   wsl --install
   ```

   Luego, dentro de WSL, instala el toolkit:
   ```bash
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
   curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add -
   curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
   sudo apt-get update
   sudo apt-get install -y nvidia-container-toolkit
   sudo systemctl restart docker
   ```

---

### 4ï¸âƒ£ Verificar que Docker Detecta la GPU

Ejecuta en PowerShell o CMD:

```bash
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

ğŸ‘‰ Si todo estÃ¡ bien, deberÃ­as ver la misma salida que con `nvidia-smi`.

---

### 5ï¸âƒ£ Flujo Recomendado Antes de Correr el Proyecto

Antes de continuar con la instalaciÃ³n del proyecto, asegÃºrate de:

- âœ… Verificar tu **GPU** con `nvidia-smi`
- âœ… Instalar/actualizar **drivers NVIDIA y CUDA**
- âœ… Instalar **Docker Desktop** con **WSL2**
- âœ… Configurar el **NVIDIA Container Toolkit**
- âœ… Probar `docker run --rm --gpus all ...` para confirmar que Docker ve la GPU

âš¡ **Una vez completados estos pasos, ya puedes continuar con:**

1. Clonar **MMPose**
2. Clonar **este repositorio dentro de la carpeta de MMPose**
3. Construir y levantar el contenedor Docker
4. Ejecutar scripts (`run_video.py`, `run_realtime.py`, etc.)

---

## ğŸ”§ Requisitos del Proyecto

Una vez completada la preparaciÃ³n del entorno, verifica que tengas:

- âœ… **Windows 11** con Docker Desktop configurado con backend WSL2
- âœ… **GPU NVIDIA** con drivers actualizados (soporte CUDA)
- âœ… **Acceso a GPU en Docker**: Ve a Docker Desktop â†’ `Settings` â†’ `Resources` â†’ `GPU` y actÃ­valo
- âœ… **Git** para clonar este repositorio

> âš ï¸ **Nota importante**: No necesitas instalar conda, miniconda ni Python localmente. Todo se ejecuta dentro del contenedor.

---

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ Dockerfile              # ConfiguraciÃ³n de la imagen Docker
â”œâ”€â”€ README.md              
â”œâ”€â”€ config.py               # ConfiguraciÃ³n de modelos y visualizaciÃ³n
â”œâ”€â”€ main.py                 # Script principal de procesamiento por lotes
â”œâ”€â”€ run_video.py            # Demo para videos pregrabados
â”œâ”€â”€ run_realtime.py         # Demo para cÃ¡mara en tiempo real
â”œâ”€â”€ video_utils.py          # Utilidades auxiliares
â”œâ”€â”€ environment.yml         # (Referencia) Dependencias conda
â”œâ”€â”€ checkpoints/            # ğŸ“¦ Coloca aquÃ­ tus archivos .pth
â”œâ”€â”€ inputs/                 # ğŸ¥ Tus videos de entrada (.mp4, .avi)
â””â”€â”€ outputs/                # ğŸ“¤ Resultados procesados
```

> ğŸ’¡ **Importante**: Los archivos `.pth` de checkpoints no se incluyen en el repositorio. Debes descargarlos manualmente y colocarlos en la carpeta `checkpoints/`.

---

## ğŸš€ GuÃ­a RÃ¡pida de Inicio

### 1. Construir la Imagen

Abre **PowerShell** en la carpeta raÃ­z del repositorio y ejecuta:

```powershell
docker build -t mmpose:cuda12.1 .
```

**Notas importantes:**
- â±ï¸ La primera construcciÃ³n puede tardar varios minutos y ocupar ~20 GB
- ğŸ”„ Las siguientes construcciones serÃ¡n mucho mÃ¡s rÃ¡pidas gracias al cachÃ©
- ğŸ“¦ El Dockerfile clona e instala MMPose automÃ¡ticamente

---

### 2. Iniciar el Contenedor

SegÃºn tu terminal, usa el comando apropiado:

**PowerShell** (Recomendado):
```powershell
docker run --gpus all --shm-size=8g -it -v ${PWD}:/workspace mmpose:cuda12.1
```

**CMD**:
```cmd
docker run --gpus all --shm-size=8g -it -v %cd%:/workspace mmpose:cuda12.1
```

**Git Bash / MINGW64**:
```bash
docker run --gpus all --shm-size=8g -it -v "$(pwd)":/workspace mmpose:cuda12.1
```

Tu proyecto quedarÃ¡ montado en `/workspace` dentro del contenedor.

---

### 3. Verificar InstalaciÃ³n

Una vez dentro del contenedor, ejecuta estas verificaciones:

**Verificar GPU y PyTorch:**
```bash
python3 -c "import torch; print(torch.__version__, torch.cuda.is_available())"
```
âœ… Salida esperada: `2.4.x True`

**Verificar MMPose:**
```bash
python3 -c "import mmpose; print('MMPose OK')"
```
âœ… Salida esperada: `MMPose OK`

---

## ğŸ¥ Uso: Procesamiento de Videos

### Paso 1: Preparar el Video

Copia tu video a la carpeta `inputs/`:
```
inputs/sample.mp4
```

### Paso 2: Procesar

Dentro del contenedor, ejecuta:

```bash
cd /workspace
python3 run_video.py --input inputs/sample.mp4 --output outputs/sample_out.mp4
```

### Paso 3: Obtener Resultados

El video procesado estarÃ¡ disponible en `outputs/sample_out.mp4`

> ğŸ’¡ **Tip**: AsegÃºrate de que tu archivo `config.py` apunte correctamente al checkpoint en `checkpoints/`

---

## ğŸ“¹ Uso: Tiempo Real (CÃ¡mara)

La captura directa de cÃ¡mara Windows â†’ contenedor Linux puede ser compleja. Te presentamos dos mÃ©todos:

### MÃ©todo A: RTSP (Recomendado)

Este mÃ©todo usa un servidor RTSP para transmitir tu cÃ¡mara al contenedor.

#### **En el Host (Windows)**

**1. Verificar FFmpeg:**
```powershell
ffmpeg -version
ffplay -version
```

**2. Listar cÃ¡maras disponibles:**
```powershell
ffmpeg -list_devices true -f dshow -i dummy
```
Anota el nombre de tu cÃ¡mara, por ejemplo: `ROG EYE S`

**3. Iniciar servidor RTSP:**

Abre una terminal y ejecuta:
```powershell
docker run --rm --name mediamtx -p 8554:8554 bluenviron/mediamtx:latest
```
âš ï¸ Deja esta terminal abierta

**4. Transmitir cÃ¡mara al servidor:**

En otra terminal, ejecuta:
```powershell
ffmpeg -f dshow -rtbufsize 256M -framerate 30 -video_size 1280x720 -i video="ROG EYE S" ^
  -vf "format=yuv420p" -c:v libx264 -preset ultrafast -tune zerolatency -pix_fmt yuv420p -g 30 ^
  -f rtsp -rtsp_transport tcp rtsp://127.0.0.1:8554/cam
```

**5. (Opcional) Verificar transmisiÃ³n:**
```powershell
ffplay rtsp://127.0.0.1:8554/cam
```

#### **En el Contenedor (Linux)**

```bash
cd /workspace
python3 run_realtime.py --input rtsp://host.docker.internal:8554/cam
```

> ğŸ”‘ **Clave**: Usa `host.docker.internal` para que el contenedor acceda a servicios del host

---

### MÃ©todo B: Usar Video como SimulaciÃ³n

Para pruebas rÃ¡pidas, usa un archivo de video:

```bash
python3 run_realtime.py --input inputs/sample.mp4
```

---

## ğŸ” SoluciÃ³n de Problemas

### Error: `ModuleNotFoundError: No module named 'mmdet'`

Algunas versiones de MMPose requieren mmdet. InstÃ¡lalo dentro del contenedor:

```bash
pip install mmdet
```

---

### La cÃ¡mara no se abre con `cv2.VideoCapture()`

- âœ… Usa el mÃ©todo RTSP con `host.docker.internal`
- âœ… Verifica que MediaMTX estÃ© corriendo
- âœ… Confirma que FFmpeg estÃ¡ transmitiendo correctamente

---

### Frames perdidos en FFmpeg

Si ves muchos `frame dropped`:

- ğŸ“‰ Reduce resoluciÃ³n: `-video_size 640x480`
- ğŸŒ Baja fps: `-framerate 25` o `-framerate 15`
- âŒ Cierra otras aplicaciones que usen la webcam

---

### GPU no detectada (`False` en `torch.cuda.is_available()`)

1. Activa GPU en Docker Desktop: `Settings` â†’ `Resources` â†’ `GPU`
2. Verifica que uses `--gpus all` al iniciar el contenedor
3. Actualiza los drivers NVIDIA en Windows
4. Revisa la secciÃ³n [PreparaciÃ³n del Entorno](#-preparaciÃ³n-del-entorno-gpu--docker) para validar la instalaciÃ³n completa

---

### Problemas con rutas de checkpoints

- Coloca los archivos `.pth` en `checkpoints/` del host
- Verifica que `config.py` apunte correctamente a estas rutas
- Las rutas dentro del contenedor serÃ¡n: `/workspace/checkpoints/`

---

## â“ Preguntas Frecuentes

<details>
<summary><strong>Â¿Necesito instalar conda o miniconda?</strong></summary>

No. Docker incluye Python y todas las dependencias necesarias. El archivo `environment.yml` es solo referencia.
</details>

<details>
<summary><strong>Â¿DÃ³nde coloco los archivos de checkpoints (.pth)?</strong></summary>

En la carpeta `checkpoints/` de tu host. Se montarÃ¡n automÃ¡ticamente en `/workspace/checkpoints` dentro del contenedor.
</details>

<details>
<summary><strong>Â¿Puedo usar mi cÃ¡mara sin RTSP?</strong></summary>

El acceso directo Windows â†’ contenedor Linux es complicado. RTSP es el mÃ©todo mÃ¡s robusto. Alternativamente, usa archivos de video para pruebas.
</details>

<details>
<summary><strong>Â¿Puedo usar una versiÃ³n especÃ­fica de MMPose?</strong></summary>

SÃ­. En el `Dockerfile`, modifica el comando `git clone` para usar un tag o commit especÃ­fico:

```dockerfile
RUN git clone --branch <tag-version> https://github.com/open-mmlab/mmpose.git
```

**Versiones probadas:**
- Python 3.8
- CUDA 12.1
- PyTorch 2.4.1+cu121
- mmcv 2.1.0
- mmengine 0.10.7
- mmdet 3.3.0
</details>

---

## ğŸ“ Comandos de Referencia RÃ¡pida

**Construir imagen:**
```bash
docker build -t mmpose:cuda12.1 .
```

**Iniciar contenedor (PowerShell):**
```bash
docker run --gpus all --shm-size=8g -it -v ${PWD}:/workspace mmpose:cuda12.1
```

**Verificar GPU:**
```bash
python3 -c "import torch; print(torch.__version__, torch.cuda.is_available())"
```

**Procesar video:**
```bash
cd /workspace
python3 run_video.py --input inputs/sample.mp4 --output outputs/sample_out.mp4
```

**Tiempo real (RTSP):**
```bash
python3 run_realtime.py --input rtsp://host.docker.internal:8554/cam
```

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request para sugerencias y mejoras.

---

<div align="center">

â­ Si este proyecto te fue Ãºtil, considera darle una estrella

</div>
